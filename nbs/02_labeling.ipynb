{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp labeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Assisted Data Analysis Notebook\n",
    "This notebook is designed for AI-assisted data labeling and querying using OpenAI's APIs. It demonstrates modular programming practices, AI-assisted labeling, and dataset querying functionalities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datasets import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Function `train_model`\n",
    "This function trains a model on labeled data. It filters out unlabeled data, encodes labels, loads a pre-trained model and tokenizer, tokenizes input data, creates a training dataset, and trains the model.\n",
    "\n",
    "\n",
    "\n",
    "## Function `evaluate_model_accuracy`\n",
    "This function (not fully visible in the provided snippet) is designed to evaluate the accuracy of the trained model, likely using the `accuracy_score` function to compare predicted labels against the true labels.\n",
    "\n",
    "\n",
    "## Function `iterative_training`\n",
    "Implements an iterative training process to refine the model with user feedback. In each iteration, it retrains the model, evaluates its accuracy, and incorporates user feedback for model refinement.\n",
    "\n",
    "\n",
    "## Function `predict_and_update_labels`\n",
    "Uses the trained model to predict labels for unlabeled data in the DataFrame. It iterates over the DataFrame, predicts labels for rows marked as 'UNLABELED', and updates the DataFrame with these labels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_model(df, model_name='bert-base-uncased', num_labels=4):\n",
    "    \"\"\"Train a model on the labeled data.\"\"\"\n",
    "    # Filter out unlabeled data\n",
    "    labeled_df = df[df['Label'] != 'UNLABELED']\n",
    "\n",
    "    # Encode labels as integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    labeled_df['EncodedLabel'] = label_encoder.fit_transform(labeled_df['Label'])\n",
    "\n",
    "    # Load a pre-trained model and tokenizer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize the input data\n",
    "    tokenized_data = tokenizer(labeled_df['Text'].tolist(), padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Create a dataset for training\n",
    "    train_dataset = Dataset.from_dict({**tokenized_data, 'labels': labeled_df['EncodedLabel'].tolist()})\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(output_dir='./results', num_train_epochs=3, per_device_train_batch_size=16)\n",
    "\n",
    "    # Initialize the Trainer\n",
    "    trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset)\n",
    "\n",
    "    # Move model to CPU\n",
    "    model.to('cpu')\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "def evaluate_model_accuracy(df, model, tokenizer):\n",
    "    \"\"\"Evaluate the model accuracy based on user labels.\"\"\"\n",
    "    labeled_df = df[df['Label'] != 'UNLABELED']\n",
    "\n",
    "    # Prepare the data for the model\n",
    "    inputs = tokenizer(labeled_df['Text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    # Move inputs to CPU\n",
    "    inputs = {k: v.to('cpu') for k, v in inputs.items()}\n",
    "\n",
    "    # Make sure the model is on CPU\n",
    "    model.to('cpu')\n",
    "\n",
    "    # Get predictions\n",
    "    outputs = model(**inputs)\n",
    "    predictions = outputs.logits.argmax(dim=1)\n",
    "\n",
    "    # Convert predictions to label names\n",
    "    label_map = {0: 'OTR', 1: 'PRS', 2: 'REP', 3: 'NEU'}\n",
    "    predicted_labels = [label_map[label] for label in predictions.numpy()]\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labeled_df['Label'].tolist(), predicted_labels)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def iterative_training(df, model, tokenizer, max_iterations=10):\n",
    "    \"\"\"Train the model iteratively, improving with user feedback.\"\"\"\n",
    "    for iteration in range(max_iterations):\n",
    "        model, tokenizer = train_model(df)\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        accuracy = evaluate_model_accuracy(df, model, tokenizer)\n",
    "        print(f\"Iteration {iteration+1}: Model Accuracy = {accuracy}\")\n",
    "\n",
    "        # Integrate with UI to get updated labels from the user\n",
    "        # df = get_updated_labels_from_ui()  # This needs to be implemented in the Streamlit script\n",
    "\n",
    "        # Check for stopping condition\n",
    "        # if stopping_condition:\n",
    "        #     break\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "# You might need to define additional helper functions or import additional libraries depending on your requirements.\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "def predict_and_update_labels(df, model, tokenizer):\n",
    "    \"\"\"Use the trained model to predict labels for unlabeled data and update the DataFrame.\"\"\"\n",
    "    # Creating a pipeline for text classification\n",
    "    text_classification_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=False)\n",
    "\n",
    "    # Define the label mapping based on your model's training\n",
    "    label_map = {0: 'OTR', 1: 'PRS', 2: 'REP', 3: 'NEU'}\n",
    "\n",
    "    # Iterating over the DataFrame and predicting labels for unlabeled rows\n",
    "    for i, row in df.iterrows():\n",
    "        if row['Label'] == 'UNLABELED':\n",
    "            # Make prediction\n",
    "            prediction = text_classification_pipeline(row['Text'])\n",
    "            predicted_label_index = int(prediction[0]['label'].split('_')[-1])  # Extract index from 'LABEL_X'\n",
    "            # Update the DataFrame with the predicted label name\n",
    "            df.at[i, 'Label'] = label_map[predicted_label_index]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "Demonstration of how this notebook can be used to iteratively train a model to label data and refine it with user feedback.\n",
    "```python\n",
    "# Load dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Initial training and labeling\n",
    "model, tokenizer = train_model(df)\n",
    "df = predict_and_update_labels(df, model, tokenizer)\n",
    "\n",
    "# Iterative training with user feedback\n",
    "for iteration in range(3):  # Example of 3 iterations\n",
    "    model, tokenizer = iterative_training(df, model, tokenizer)\n",
    "    df = predict_and_update_labels(df, model, tokenizer)\n",
    "    # Incorporate user feedback here\n",
    "\n",
    "# Evaluate final model accuracy\n",
    "accuracy = evaluate_model_accuracy(df, model, tokenizer)\n",
    "print(f\"Final Model Accuracy: {accuracy}\")\n",
    "\n",
    "# Save the labeled data\n",
    "df.to_csv('labeled_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
